{"title":"关于深度学习Pytorch","slug":"deeepstudy","date":"2021-12-01T03:34:19.000Z","updated":"2024-04-18T15:18:16.845Z","comments":true,"path":"api/articles/deeepstudy.json","excerpt":null,"covers":["../images/1.2/tensor%E7%9A%84%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B.png"],"content":"<h2 id=\"深度学习\"><a href=\"#深度学习\" class=\"headerlink\" title=\"深度学习\"></a>深度学习</h2><ul>\n<li>机器语言的分支, 对数据进行特征学习, 人工神经网络为基础</li>\n</ul>\n<h3 id=\"机器学习和深度学习的区别\"><a href=\"#机器学习和深度学习的区别\" class=\"headerlink\" title=\"机器学习和深度学习的区别\"></a>机器学习和深度学习的区别</h3><ul>\n<li>特征抽取:<ol>\n<li>人工的特征抽取的过程</li>\n<li>深度学习：自动的进行特征抽取</li>\n</ol>\n</li>\n<li>数据量:<ol>\n<li>机器学习：数据少</li>\n<li>深度学习：数据多</li>\n</ol>\n</li>\n</ul>\n<h3 id=\"深度学习的应用场景\"><a href=\"#深度学习的应用场景\" class=\"headerlink\" title=\"深度学习的应用场景\"></a>深度学习的应用场景</h3><ol>\n<li>图像识别：物体识别场景识别人脸检测跟踪人脸身份认证自然语言处理技术</li>\n<li>机器翻译：文本识别聊天对话语音技术</li>\n<li>语音识别</li>\n</ol>\n<h3 id=\"神经网络\"><a href=\"#神经网络\" class=\"headerlink\" title=\"神经网络\"></a>神经网络</h3><ol>\n<li>人工神经网络（英语：Artificial Neural Network，ANN），简称神经网络（Neural Network，NN）或类神经网络，是一种模仿生物神经网络（动物的中枢神经系统，特别是大脑）的结构和功能的数学模型，用于对函数进行估计或近似。<br>和其他机器学习方法一样, 神经网络已经被用于解决各种各样的问题, 例如机器视觉和语音识别. 这些问题都是很难被传统基于规则的编程所解决的.</li>\n<li>模拟生物的神经元，对函数进行评估或者近似。神经网络中的基础单元，相互连接，组成神经网络</li>\n<li><code>t=f(W^TA+b)</code> 一个神经元的功能是求得输入向量与权向量的内积后, 经一个非线性传递函数得到一个标量结果.</li>\n</ol>\n<h3 id=\"单项神经网络\"><a href=\"#单项神经网络\" class=\"headerlink\" title=\"单项神经网络\"></a>单项神经网络</h3><ul>\n<li>最基本的神经元形式由有限个神经元构成, 所有神经元的输入向量都是同一个向量. 由于每一个神经元都会产生一个标量结果, 所以单层神经元的输出是一个向量, 向量的维数等于神经元的数目.</li>\n</ul>\n<h3 id=\"感知机\"><a href=\"#感知机\" class=\"headerlink\" title=\"感知机\"></a>感知机</h3><ul>\n<li>两层神经网络组成, 输出层输入层, 感知机由两层神经网络组成, 输入层接收外界输入信号后传递给输出层(输出+1正例, -1反例), 输出层是 M-P 神经元</li>\n<li>作用: 把一个n维向量空间用一个超平面分割成两部分, 给定一个输入向量, 超平面可以判断出这个向量位于超平面的哪一边, 得到输入时正类或者是反类, 对应到2维空间就是一条直线把一个平面分为两个部分.</li>\n</ul>\n<h2 id=\"初步使用\"><a href=\"#初步使用\" class=\"headerlink\" title=\"初步使用\"></a>初步使用</h2><h3 id=\"Pytorch的入门使用\"><a href=\"#Pytorch的入门使用\" class=\"headerlink\" title=\"Pytorch的入门使用\"></a>Pytorch的入门使用</h3><h2 id=\"目标\"><a href=\"#目标\" class=\"headerlink\" title=\"目标\"></a>目标</h2><ol>\n<li>知道张量和Pytorch中的张量</li>\n<li>知道pytorch中如何创建张量</li>\n<li>知道pytorch中tensor的常见方法</li>\n<li>知道pytorch中tensor的数据类型</li>\n<li>知道pytorch中如何实现tensor在cpu和cuda中转化</li>\n</ol>\n<h2 id=\"1-张量Tensor\"><a href=\"#1-张量Tensor\" class=\"headerlink\" title=\"1. 张量Tensor\"></a>1. 张量Tensor</h2><p>张量是一个统称, 其中包含很多类型:</p>\n<ol>\n<li>0阶张量：标量、常数，0-D Tensor</li>\n<li>1阶张量：向量，1-D Tensor</li>\n<li>2阶张量：矩阵，2-D Tensor</li>\n<li>3阶张量</li>\n<li>…</li>\n<li>N阶张量</li>\n</ol>\n<h2 id=\"2-Pytorch中创建张量\"><a href=\"#2-Pytorch中创建张量\" class=\"headerlink\" title=\"2. Pytorch中创建张量\"></a>2. Pytorch中创建张量</h2><ol>\n<li>使用python中的列表或者序列创建tensor</li>\n</ol>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">torch.tensor([[<span class=\"number\">1.</span>, -<span class=\"number\">1.</span>], [<span class=\"number\">1.</span>, -<span class=\"number\">1.</span>]])</span><br><span class=\"line\">tensor([[ <span class=\"number\">1.0000</span>, -<span class=\"number\">1.0000</span>],</span><br><span class=\"line\">        [ <span class=\"number\">1.0000</span>, -<span class=\"number\">1.0000</span>]])</span><br></pre></td></tr></table></figure>\n<ol start=\"2\">\n<li>使用numpy中的数组创建tensor</li>\n</ol>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">torch.tensor(np.array([[<span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">3</span>], [<span class=\"number\">4</span>, <span class=\"number\">5</span>, <span class=\"number\">6</span>]]))</span><br><span class=\"line\">tensor([[ <span class=\"number\">1</span>,  <span class=\"number\">2</span>,  <span class=\"number\">3</span>],</span><br><span class=\"line\">        [ <span class=\"number\">4</span>,  <span class=\"number\">5</span>,  <span class=\"number\">6</span>]])</span><br></pre></td></tr></table></figure>\n<ol start=\"3\">\n<li><p>使用torch的api创建tensor</p>\n</li>\n<li><p><code>torch.empty(3, 4)</code> 创建3行4列的空的tensor, 会用无用数据进行填充</p>\n</li>\n<li><p><code>torch.ones([3,4])</code> 创建3行4列的<strong>全为1</strong>的tensor</p>\n</li>\n<li><p><code>torch.zeros([3, 4])</code> 创建3行4列的<strong>全为0</strong>的tensor</p>\n</li>\n<li><p><code>torch.rand([3,4])</code> 创建3行4列的<strong>随机值</strong>的tensor, 随机值的区间是 <code>[0, 1)</code></p>\n</li>\n</ol>\n<figure class=\"highlight js\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>torch.rand(<span class=\"number\">2</span>, <span class=\"number\">3</span>)</span><br><span class=\"line\">tensor([[ <span class=\"number\">0.8237</span>,  <span class=\"number\">0.5781</span>,  <span class=\"number\">0.6879</span>],</span><br><span class=\"line\">[ <span class=\"number\">0.3816</span>,  <span class=\"number\">0.7249</span>,  <span class=\"number\">0.0998</span>]])</span><br></pre></td></tr></table></figure>\n<ol start=\"5\">\n<li><code>torch.randint(low=0,high=10,size=[3,4])</code> 创建3行4列的<strong>随机整数</strong>的tensor, 随机值的区间是 <code>[low, high)</code></li>\n</ol>\n<figure class=\"highlight js\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>torch.randint(<span class=\"number\">3</span>, <span class=\"number\">10</span>, (<span class=\"number\">2</span>, <span class=\"number\">2</span>))</span><br><span class=\"line\">tensor([[<span class=\"number\">4</span>, <span class=\"number\">5</span>],</span><br><span class=\"line\">\t[<span class=\"number\">6</span>, <span class=\"number\">7</span>]])</span><br></pre></td></tr></table></figure>\n<ol start=\"6\">\n<li><code>torch.randn([3,4])</code> 创建3行4列的<strong>随机数</strong>的tensor, 随机值的分布式均值为0, 方差为1</li>\n</ol>\n<h2 id=\"3-Pytorch中tensor的常用方法\"><a href=\"#3-Pytorch中tensor的常用方法\" class=\"headerlink\" title=\"3. Pytorch中tensor的常用方法\"></a>3. Pytorch中tensor的常用方法</h2><ol>\n<li>获取tensor中的数据(当tensor中只有一个元素可用)：<code>tensor.item()</code></li>\n</ol>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">In [<span class=\"number\">10</span>]: a = torch.tensor(np.arange(<span class=\"number\">1</span>))</span><br><span class=\"line\"> </span><br><span class=\"line\">In [<span class=\"number\">11</span>]: a</span><br><span class=\"line\">Out[<span class=\"number\">11</span>]: tensor([<span class=\"number\">0</span>])</span><br><span class=\"line\"> </span><br><span class=\"line\">In [<span class=\"number\">12</span>]: a.item()</span><br><span class=\"line\">Out[<span class=\"number\">12</span>]: <span class=\"number\">0</span></span><br></pre></td></tr></table></figure>\n<ol start=\"2\">\n<li>转化为numpy数组</li>\n</ol>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">In [<span class=\"number\">55</span>]: z.numpy()</span><br><span class=\"line\">Out[<span class=\"number\">55</span>]:</span><br><span class=\"line\">array([[-<span class=\"number\">2.5871205</span>],</span><br><span class=\"line\">       [ <span class=\"number\">7.3690367</span>],</span><br><span class=\"line\">       [-<span class=\"number\">2.4918075</span>]], dtype=float32)</span><br></pre></td></tr></table></figure>\n<ol start=\"3\">\n<li>获取形状：<code>tensor.size()</code></li>\n</ol>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">In [<span class=\"number\">72</span>]: x</span><br><span class=\"line\">Out[<span class=\"number\">72</span>]:</span><br><span class=\"line\">tensor([[    <span class=\"number\">1</span>,     <span class=\"number\">2</span>],</span><br><span class=\"line\">        [    <span class=\"number\">3</span>,     <span class=\"number\">4</span>],</span><br><span class=\"line\">        [    <span class=\"number\">5</span>,    <span class=\"number\">10</span>]], dtype=torch.int32)</span><br><span class=\"line\"> </span><br><span class=\"line\">In [<span class=\"number\">73</span>]: x.size()</span><br><span class=\"line\">Out[<span class=\"number\">73</span>]: torch.Size([<span class=\"number\">3</span>, <span class=\"number\">2</span>])</span><br></pre></td></tr></table></figure>\n<ol start=\"4\">\n<li>形状改变：<code>tensor.view((3,4))</code>。类似numpy中的reshape，是一种浅拷贝，仅仅是形状发生改变</li>\n</ol>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">In [<span class=\"number\">76</span>]: x.view(<span class=\"number\">2</span>,<span class=\"number\">3</span>)</span><br><span class=\"line\">Out[<span class=\"number\">76</span>]:</span><br><span class=\"line\">tensor([[    <span class=\"number\">1</span>,     <span class=\"number\">2</span>,     <span class=\"number\">3</span>],</span><br><span class=\"line\">        [    <span class=\"number\">4</span>,     <span class=\"number\">5</span>,    <span class=\"number\">10</span>]], dtype=torch.int32)</span><br></pre></td></tr></table></figure>\n<ol start=\"5\">\n<li>获取阶数：<code>tensor.dim()</code></li>\n</ol>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">In [<span class=\"number\">77</span>]: x.dim()</span><br><span class=\"line\">Out[<span class=\"number\">77</span>]: <span class=\"number\">2</span></span><br></pre></td></tr></table></figure>\n<ol start=\"6\">\n<li>获取最大值：<code>tensor.max()</code></li>\n</ol>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">In [<span class=\"number\">78</span>]: x.<span class=\"built_in\">max</span>()</span><br><span class=\"line\">Out[<span class=\"number\">78</span>]: tensor(<span class=\"number\">10</span>, dtype=torch.int32)</span><br></pre></td></tr></table></figure>\n<ol start=\"7\">\n<li>转置：<code>tensor.t()</code></li>\n</ol>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">In [<span class=\"number\">79</span>]: x.t()</span><br><span class=\"line\">Out[<span class=\"number\">79</span>]:</span><br><span class=\"line\">tensor([[    <span class=\"number\">1</span>,     <span class=\"number\">3</span>,     <span class=\"number\">5</span>],</span><br><span class=\"line\">        [    <span class=\"number\">2</span>,     <span class=\"number\">4</span>, \t  <span class=\"number\">10</span>]], dtype=torch.int32)</span><br></pre></td></tr></table></figure>\n<ol start=\"8\">\n<li><p><code>tensor[1,3]</code>  获取tensor中第一行第三列的值</p>\n</li>\n<li><p><code>tensor[1,3]=100</code> 对tensor中第一行第三列的位置进行赋值100</p>\n</li>\n<li><p>tensor的切片</p>\n</li>\n</ol>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">In [<span class=\"number\">101</span>]: x</span><br><span class=\"line\">Out[<span class=\"number\">101</span>]:</span><br><span class=\"line\">tensor([[<span class=\"number\">1.6437</span>, <span class=\"number\">1.9439</span>, <span class=\"number\">1.5393</span>],</span><br><span class=\"line\">        [<span class=\"number\">1.3491</span>, <span class=\"number\">1.9575</span>, <span class=\"number\">1.0552</span>],</span><br><span class=\"line\">        [<span class=\"number\">1.5106</span>, <span class=\"number\">1.0123</span>, <span class=\"number\">1.0961</span>],</span><br><span class=\"line\">        [<span class=\"number\">1.4382</span>, <span class=\"number\">1.5939</span>, <span class=\"number\">1.5012</span>],</span><br><span class=\"line\">        [<span class=\"number\">1.5267</span>, <span class=\"number\">1.4858</span>, <span class=\"number\">1.4007</span>]])</span><br><span class=\"line\"> </span><br><span class=\"line\">In [<span class=\"number\">102</span>]: x[:,<span class=\"number\">1</span>]</span><br><span class=\"line\">Out[<span class=\"number\">102</span>]: tensor([<span class=\"number\">1.9439</span>, <span class=\"number\">1.9575</span>, <span class=\"number\">1.0123</span>, <span class=\"number\">1.5939</span>, <span class=\"number\">1.4858</span>])</span><br></pre></td></tr></table></figure>\n<p>​</p>\n<h2 id=\"4-tensor的数据类型\"><a href=\"#4-tensor的数据类型\" class=\"headerlink\" title=\"4. tensor的数据类型\"></a>4. tensor的数据类型</h2><p>tensor中的数据类型非常多, 常见类型如下:</p>\n<p><img src=\"../images/1.2/tensor%E7%9A%84%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B.png\"></p>\n<p>上图中的Tensor types表示这种type的tensor是其实例</p>\n<ol>\n<li>获取tensor的数据类型:<code>tensor.dtype</code></li>\n</ol>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">In [<span class=\"number\">80</span>]: x.dtype</span><br><span class=\"line\">Out[<span class=\"number\">80</span>]: torch.int32</span><br></pre></td></tr></table></figure>\n<ol start=\"2\">\n<li>创建数据的时候指定类型</li>\n</ol>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">In [<span class=\"number\">88</span>]: torch.ones([<span class=\"number\">2</span>,<span class=\"number\">3</span>],dtype=torch.float32)</span><br><span class=\"line\">Out[<span class=\"number\">88</span>]:</span><br><span class=\"line\">tensor([[<span class=\"number\">9.1167e+18</span>, <span class=\"number\">0.0000e+00</span>, <span class=\"number\">7.8796e+15</span>],</span><br><span class=\"line\">        [<span class=\"number\">8.3097e-43</span>, <span class=\"number\">0.0000e+00</span>, -<span class=\"number\">0.0000e+00</span>]])</span><br></pre></td></tr></table></figure>\n<ol start=\"3\">\n<li>类型的修改</li>\n</ol>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">In [<span class=\"number\">17</span>]: a</span><br><span class=\"line\">Out[<span class=\"number\">17</span>]: tensor([<span class=\"number\">1</span>, <span class=\"number\">2</span>], dtype=torch.int32)</span><br><span class=\"line\"> </span><br><span class=\"line\">In [<span class=\"number\">18</span>]: a.<span class=\"built_in\">type</span>(torch.<span class=\"built_in\">float</span>)</span><br><span class=\"line\">Out[<span class=\"number\">18</span>]: tensor([<span class=\"number\">1.</span>, <span class=\"number\">2.</span>])</span><br><span class=\"line\"> </span><br><span class=\"line\">In [<span class=\"number\">19</span>]: a.double()</span><br><span class=\"line\">Out[<span class=\"number\">19</span>]: tensor([<span class=\"number\">1.</span>, <span class=\"number\">2.</span>], dtype=torch.float64)</span><br></pre></td></tr></table></figure>\n<h2 id=\"5-tensor的其他操作\"><a href=\"#5-tensor的其他操作\" class=\"headerlink\" title=\"5. tensor的其他操作\"></a>5. tensor的其他操作</h2><ol>\n<li>tensor和tensor相加</li>\n</ol>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">In [<span class=\"number\">94</span>]: x = x.new_ones(<span class=\"number\">5</span>, <span class=\"number\">3</span>, dtype=torch.<span class=\"built_in\">float</span>)</span><br><span class=\"line\"> </span><br><span class=\"line\">In [<span class=\"number\">95</span>]: y = torch.rand(<span class=\"number\">5</span>, <span class=\"number\">3</span>)</span><br><span class=\"line\"> </span><br><span class=\"line\">In [<span class=\"number\">96</span>]: x+y</span><br><span class=\"line\">Out[<span class=\"number\">96</span>]:</span><br><span class=\"line\">tensor([[<span class=\"number\">1.6437</span>, <span class=\"number\">1.9439</span>, <span class=\"number\">1.5393</span>],</span><br><span class=\"line\">        [<span class=\"number\">1.3491</span>, <span class=\"number\">1.9575</span>, <span class=\"number\">1.0552</span>],</span><br><span class=\"line\">        [<span class=\"number\">1.5106</span>, <span class=\"number\">1.0123</span>, <span class=\"number\">1.0961</span>],</span><br><span class=\"line\">        [<span class=\"number\">1.4382</span>, <span class=\"number\">1.5939</span>, <span class=\"number\">1.5012</span>],</span><br><span class=\"line\">        [<span class=\"number\">1.5267</span>, <span class=\"number\">1.4858</span>, <span class=\"number\">1.4007</span>]])</span><br><span class=\"line\">In [<span class=\"number\">98</span>]: torch.add(x,y)</span><br><span class=\"line\">Out[<span class=\"number\">98</span>]:</span><br><span class=\"line\">tensor([[<span class=\"number\">1.6437</span>, <span class=\"number\">1.9439</span>, <span class=\"number\">1.5393</span>],</span><br><span class=\"line\">        [<span class=\"number\">1.3491</span>, <span class=\"number\">1.9575</span>, <span class=\"number\">1.0552</span>],</span><br><span class=\"line\">        [<span class=\"number\">1.5106</span>, <span class=\"number\">1.0123</span>, <span class=\"number\">1.0961</span>],</span><br><span class=\"line\">        [<span class=\"number\">1.4382</span>, <span class=\"number\">1.5939</span>, <span class=\"number\">1.5012</span>],</span><br><span class=\"line\">        [<span class=\"number\">1.5267</span>, <span class=\"number\">1.4858</span>, <span class=\"number\">1.4007</span>]])</span><br><span class=\"line\">In [<span class=\"number\">99</span>]: x.add(y)</span><br><span class=\"line\">Out[<span class=\"number\">99</span>]:</span><br><span class=\"line\">tensor([[<span class=\"number\">1.6437</span>, <span class=\"number\">1.9439</span>, <span class=\"number\">1.5393</span>],</span><br><span class=\"line\">        [<span class=\"number\">1.3491</span>, <span class=\"number\">1.9575</span>, <span class=\"number\">1.0552</span>],</span><br><span class=\"line\">        [<span class=\"number\">1.5106</span>, <span class=\"number\">1.0123</span>, <span class=\"number\">1.0961</span>],</span><br><span class=\"line\">        [<span class=\"number\">1.4382</span>, <span class=\"number\">1.5939</span>, <span class=\"number\">1.5012</span>],</span><br><span class=\"line\">        [<span class=\"number\">1.5267</span>, <span class=\"number\">1.4858</span>, <span class=\"number\">1.4007</span>]])</span><br><span class=\"line\">In [<span class=\"number\">100</span>]: x.add_(y)  <span class=\"comment\">#带下划线的方法会对x进行就地修改</span></span><br><span class=\"line\">Out[<span class=\"number\">100</span>]:</span><br><span class=\"line\">tensor([[<span class=\"number\">1.6437</span>, <span class=\"number\">1.9439</span>, <span class=\"number\">1.5393</span>],</span><br><span class=\"line\">        [<span class=\"number\">1.3491</span>, <span class=\"number\">1.9575</span>, <span class=\"number\">1.0552</span>],</span><br><span class=\"line\">        [<span class=\"number\">1.5106</span>, <span class=\"number\">1.0123</span>, <span class=\"number\">1.0961</span>],</span><br><span class=\"line\">        [<span class=\"number\">1.4382</span>, <span class=\"number\">1.5939</span>, <span class=\"number\">1.5012</span>],</span><br><span class=\"line\">        [<span class=\"number\">1.5267</span>, <span class=\"number\">1.4858</span>, <span class=\"number\">1.4007</span>]])</span><br><span class=\"line\"> </span><br><span class=\"line\">In [<span class=\"number\">101</span>]: x <span class=\"comment\">#x发生改变</span></span><br><span class=\"line\">Out[<span class=\"number\">101</span>]:</span><br><span class=\"line\">tensor([[<span class=\"number\">1.6437</span>, <span class=\"number\">1.9439</span>, <span class=\"number\">1.5393</span>],</span><br><span class=\"line\">        [<span class=\"number\">1.3491</span>, <span class=\"number\">1.9575</span>, <span class=\"number\">1.0552</span>],</span><br><span class=\"line\">        [<span class=\"number\">1.5106</span>, <span class=\"number\">1.0123</span>, <span class=\"number\">1.0961</span>],</span><br><span class=\"line\">        [<span class=\"number\">1.4382</span>, <span class=\"number\">1.5939</span>, <span class=\"number\">1.5012</span>],</span><br><span class=\"line\">        [<span class=\"number\">1.5267</span>, <span class=\"number\">1.4858</span>, <span class=\"number\">1.4007</span>]])</span><br></pre></td></tr></table></figure>\n<p>   注意: 带下划线的方法(比如: <code>add_</code> )会对tensor进行就地修改</p>\n<ol start=\"2\">\n<li>tensor和数字操作</li>\n</ol>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">In [<span class=\"number\">97</span>]: x +<span class=\"number\">10</span></span><br><span class=\"line\">Out[<span class=\"number\">97</span>]:</span><br><span class=\"line\">tensor([[<span class=\"number\">11.</span>, <span class=\"number\">11.</span>, <span class=\"number\">11.</span>],</span><br><span class=\"line\">        [<span class=\"number\">11.</span>, <span class=\"number\">11.</span>, <span class=\"number\">11.</span>],</span><br><span class=\"line\">        [<span class=\"number\">11.</span>, <span class=\"number\">11.</span>, <span class=\"number\">11.</span>],</span><br><span class=\"line\">        [<span class=\"number\">11.</span>, <span class=\"number\">11.</span>, <span class=\"number\">11.</span>],</span><br><span class=\"line\">        [<span class=\"number\">11.</span>, <span class=\"number\">11.</span>, <span class=\"number\">11.</span>]])</span><br></pre></td></tr></table></figure>\n<ol start=\"3\">\n<li><p>CUDA中的tensor</p>\n<p>CUDA(Compute Unified Device Architecture), 是NVIDIA推出的运算平台. CUDA™是一种由NVIDIA推出的通用并行计算架构, 该架构使GPU能够解决复杂的计算问题.</p>\n</li>\n</ol>\n<p><code>torch.cuda</code> 这个模块增加了对CUDA tensor的支持, 能够在cpu和gpu上使用相同的方法操作tensor</p>\n<p>   通过 <code>.to</code> 方法能够把一个tensor转移到另外一个设备(比如从CPU转到GPU)</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#device = torch.device(&quot;cuda:0&quot; if torch.cuda.is_available() else &quot;cpu&quot;)</span></span><br><span class=\"line\"><span class=\"keyword\">if</span> torch.cuda.is_available():</span><br><span class=\"line\">    device = torch.device(<span class=\"string\">&quot;cuda&quot;</span>)          <span class=\"comment\"># cuda device对象</span></span><br><span class=\"line\">    y = torch.ones_like(x, device=device)  <span class=\"comment\"># 创建一个在cuda上的tensor</span></span><br><span class=\"line\">    x = x.to(device)                       <span class=\"comment\"># 使用方法把x转为cuda 的tensor</span></span><br><span class=\"line\">    z = x + y</span><br><span class=\"line\">    print(z)</span><br><span class=\"line\">    print(z.to(<span class=\"string\">&quot;cpu&quot;</span>, torch.double))       <span class=\"comment\"># .to方法也能够同时设置类型</span></span><br><span class=\"line\"></span><br><span class=\"line\">&gt;&gt;tensor([<span class=\"number\">1.9806</span>], device=<span class=\"string\">&#x27;cuda:0&#x27;</span>)</span><br><span class=\"line\">&gt;&gt;tensor([<span class=\"number\">1.9806</span>], dtype=torch.float64)</span><br></pre></td></tr></table></figure>\n<p>通过前面的学习, 可以发现torch的各种操作几乎和numpy一样</p>\n","more":"<h2 id=\"深度学习\"><a href=\"#深度学习\" class=\"headerlink\" title=\"深度学习\"></a>深度学习</h2><ul>\n<li>机器语言的分支, 对数据进行特征学习, 人工神经网络为基础</li>\n</ul>\n<h3 id=\"机器学习和深度学习的区别\"><a href=\"#机器学习和深度学习的区别\" class=\"headerlink\" title=\"机器学习和深度学习的区别\"></a>机器学习和深度学习的区别</h3><ul>\n<li>特征抽取:<ol>\n<li>人工的特征抽取的过程</li>\n<li>深度学习：自动的进行特征抽取</li>\n</ol>\n</li>\n<li>数据量:<ol>\n<li>机器学习：数据少</li>\n<li>深度学习：数据多</li>\n</ol>\n</li>\n</ul>\n<h3 id=\"深度学习的应用场景\"><a href=\"#深度学习的应用场景\" class=\"headerlink\" title=\"深度学习的应用场景\"></a>深度学习的应用场景</h3><ol>\n<li>图像识别：物体识别场景识别人脸检测跟踪人脸身份认证自然语言处理技术</li>\n<li>机器翻译：文本识别聊天对话语音技术</li>\n<li>语音识别</li>\n</ol>\n<h3 id=\"神经网络\"><a href=\"#神经网络\" class=\"headerlink\" title=\"神经网络\"></a>神经网络</h3><ol>\n<li>人工神经网络（英语：Artificial Neural Network，ANN），简称神经网络（Neural Network，NN）或类神经网络，是一种模仿生物神经网络（动物的中枢神经系统，特别是大脑）的结构和功能的数学模型，用于对函数进行估计或近似。<br>和其他机器学习方法一样, 神经网络已经被用于解决各种各样的问题, 例如机器视觉和语音识别. 这些问题都是很难被传统基于规则的编程所解决的.</li>\n<li>模拟生物的神经元，对函数进行评估或者近似。神经网络中的基础单元，相互连接，组成神经网络</li>\n<li><code>t=f(W^TA+b)</code> 一个神经元的功能是求得输入向量与权向量的内积后, 经一个非线性传递函数得到一个标量结果.</li>\n</ol>\n<h3 id=\"单项神经网络\"><a href=\"#单项神经网络\" class=\"headerlink\" title=\"单项神经网络\"></a>单项神经网络</h3><ul>\n<li>最基本的神经元形式由有限个神经元构成, 所有神经元的输入向量都是同一个向量. 由于每一个神经元都会产生一个标量结果, 所以单层神经元的输出是一个向量, 向量的维数等于神经元的数目.</li>\n</ul>\n<h3 id=\"感知机\"><a href=\"#感知机\" class=\"headerlink\" title=\"感知机\"></a>感知机</h3><ul>\n<li>两层神经网络组成, 输出层输入层, 感知机由两层神经网络组成, 输入层接收外界输入信号后传递给输出层(输出+1正例, -1反例), 输出层是 M-P 神经元</li>\n<li>作用: 把一个n维向量空间用一个超平面分割成两部分, 给定一个输入向量, 超平面可以判断出这个向量位于超平面的哪一边, 得到输入时正类或者是反类, 对应到2维空间就是一条直线把一个平面分为两个部分.</li>\n</ul>\n<h2 id=\"初步使用\"><a href=\"#初步使用\" class=\"headerlink\" title=\"初步使用\"></a>初步使用</h2><h3 id=\"Pytorch的入门使用\"><a href=\"#Pytorch的入门使用\" class=\"headerlink\" title=\"Pytorch的入门使用\"></a>Pytorch的入门使用</h3><h2 id=\"目标\"><a href=\"#目标\" class=\"headerlink\" title=\"目标\"></a>目标</h2><ol>\n<li>知道张量和Pytorch中的张量</li>\n<li>知道pytorch中如何创建张量</li>\n<li>知道pytorch中tensor的常见方法</li>\n<li>知道pytorch中tensor的数据类型</li>\n<li>知道pytorch中如何实现tensor在cpu和cuda中转化</li>\n</ol>\n<h2 id=\"1-张量Tensor\"><a href=\"#1-张量Tensor\" class=\"headerlink\" title=\"1. 张量Tensor\"></a>1. 张量Tensor</h2><p>张量是一个统称, 其中包含很多类型:</p>\n<ol>\n<li>0阶张量：标量、常数，0-D Tensor</li>\n<li>1阶张量：向量，1-D Tensor</li>\n<li>2阶张量：矩阵，2-D Tensor</li>\n<li>3阶张量</li>\n<li>…</li>\n<li>N阶张量</li>\n</ol>\n<h2 id=\"2-Pytorch中创建张量\"><a href=\"#2-Pytorch中创建张量\" class=\"headerlink\" title=\"2. Pytorch中创建张量\"></a>2. Pytorch中创建张量</h2><ol>\n<li>使用python中的列表或者序列创建tensor</li>\n</ol>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">torch.tensor([[<span class=\"number\">1.</span>, -<span class=\"number\">1.</span>], [<span class=\"number\">1.</span>, -<span class=\"number\">1.</span>]])</span><br><span class=\"line\">tensor([[ <span class=\"number\">1.0000</span>, -<span class=\"number\">1.0000</span>],</span><br><span class=\"line\">        [ <span class=\"number\">1.0000</span>, -<span class=\"number\">1.0000</span>]])</span><br></pre></td></tr></table></figure>\n<ol start=\"2\">\n<li>使用numpy中的数组创建tensor</li>\n</ol>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">torch.tensor(np.array([[<span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">3</span>], [<span class=\"number\">4</span>, <span class=\"number\">5</span>, <span class=\"number\">6</span>]]))</span><br><span class=\"line\">tensor([[ <span class=\"number\">1</span>,  <span class=\"number\">2</span>,  <span class=\"number\">3</span>],</span><br><span class=\"line\">        [ <span class=\"number\">4</span>,  <span class=\"number\">5</span>,  <span class=\"number\">6</span>]])</span><br></pre></td></tr></table></figure>\n<ol start=\"3\">\n<li><p>使用torch的api创建tensor</p>\n</li>\n<li><p><code>torch.empty(3, 4)</code> 创建3行4列的空的tensor, 会用无用数据进行填充</p>\n</li>\n<li><p><code>torch.ones([3,4])</code> 创建3行4列的<strong>全为1</strong>的tensor</p>\n</li>\n<li><p><code>torch.zeros([3, 4])</code> 创建3行4列的<strong>全为0</strong>的tensor</p>\n</li>\n<li><p><code>torch.rand([3,4])</code> 创建3行4列的<strong>随机值</strong>的tensor, 随机值的区间是 <code>[0, 1)</code></p>\n</li>\n</ol>\n<figure class=\"highlight js\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>torch.rand(<span class=\"number\">2</span>, <span class=\"number\">3</span>)</span><br><span class=\"line\">tensor([[ <span class=\"number\">0.8237</span>,  <span class=\"number\">0.5781</span>,  <span class=\"number\">0.6879</span>],</span><br><span class=\"line\">[ <span class=\"number\">0.3816</span>,  <span class=\"number\">0.7249</span>,  <span class=\"number\">0.0998</span>]])</span><br></pre></td></tr></table></figure>\n<ol start=\"5\">\n<li><code>torch.randint(low=0,high=10,size=[3,4])</code> 创建3行4列的<strong>随机整数</strong>的tensor, 随机值的区间是 <code>[low, high)</code></li>\n</ol>\n<figure class=\"highlight js\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>torch.randint(<span class=\"number\">3</span>, <span class=\"number\">10</span>, (<span class=\"number\">2</span>, <span class=\"number\">2</span>))</span><br><span class=\"line\">tensor([[<span class=\"number\">4</span>, <span class=\"number\">5</span>],</span><br><span class=\"line\">\t[<span class=\"number\">6</span>, <span class=\"number\">7</span>]])</span><br></pre></td></tr></table></figure>\n<ol start=\"6\">\n<li><code>torch.randn([3,4])</code> 创建3行4列的<strong>随机数</strong>的tensor, 随机值的分布式均值为0, 方差为1</li>\n</ol>\n<h2 id=\"3-Pytorch中tensor的常用方法\"><a href=\"#3-Pytorch中tensor的常用方法\" class=\"headerlink\" title=\"3. Pytorch中tensor的常用方法\"></a>3. Pytorch中tensor的常用方法</h2><ol>\n<li>获取tensor中的数据(当tensor中只有一个元素可用)：<code>tensor.item()</code></li>\n</ol>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">In [<span class=\"number\">10</span>]: a = torch.tensor(np.arange(<span class=\"number\">1</span>))</span><br><span class=\"line\"> </span><br><span class=\"line\">In [<span class=\"number\">11</span>]: a</span><br><span class=\"line\">Out[<span class=\"number\">11</span>]: tensor([<span class=\"number\">0</span>])</span><br><span class=\"line\"> </span><br><span class=\"line\">In [<span class=\"number\">12</span>]: a.item()</span><br><span class=\"line\">Out[<span class=\"number\">12</span>]: <span class=\"number\">0</span></span><br></pre></td></tr></table></figure>\n<ol start=\"2\">\n<li>转化为numpy数组</li>\n</ol>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">In [<span class=\"number\">55</span>]: z.numpy()</span><br><span class=\"line\">Out[<span class=\"number\">55</span>]:</span><br><span class=\"line\">array([[-<span class=\"number\">2.5871205</span>],</span><br><span class=\"line\">       [ <span class=\"number\">7.3690367</span>],</span><br><span class=\"line\">       [-<span class=\"number\">2.4918075</span>]], dtype=float32)</span><br></pre></td></tr></table></figure>\n<ol start=\"3\">\n<li>获取形状：<code>tensor.size()</code></li>\n</ol>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">In [<span class=\"number\">72</span>]: x</span><br><span class=\"line\">Out[<span class=\"number\">72</span>]:</span><br><span class=\"line\">tensor([[    <span class=\"number\">1</span>,     <span class=\"number\">2</span>],</span><br><span class=\"line\">        [    <span class=\"number\">3</span>,     <span class=\"number\">4</span>],</span><br><span class=\"line\">        [    <span class=\"number\">5</span>,    <span class=\"number\">10</span>]], dtype=torch.int32)</span><br><span class=\"line\"> </span><br><span class=\"line\">In [<span class=\"number\">73</span>]: x.size()</span><br><span class=\"line\">Out[<span class=\"number\">73</span>]: torch.Size([<span class=\"number\">3</span>, <span class=\"number\">2</span>])</span><br></pre></td></tr></table></figure>\n<ol start=\"4\">\n<li>形状改变：<code>tensor.view((3,4))</code>。类似numpy中的reshape，是一种浅拷贝，仅仅是形状发生改变</li>\n</ol>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">In [<span class=\"number\">76</span>]: x.view(<span class=\"number\">2</span>,<span class=\"number\">3</span>)</span><br><span class=\"line\">Out[<span class=\"number\">76</span>]:</span><br><span class=\"line\">tensor([[    <span class=\"number\">1</span>,     <span class=\"number\">2</span>,     <span class=\"number\">3</span>],</span><br><span class=\"line\">        [    <span class=\"number\">4</span>,     <span class=\"number\">5</span>,    <span class=\"number\">10</span>]], dtype=torch.int32)</span><br></pre></td></tr></table></figure>\n<ol start=\"5\">\n<li>获取阶数：<code>tensor.dim()</code></li>\n</ol>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">In [<span class=\"number\">77</span>]: x.dim()</span><br><span class=\"line\">Out[<span class=\"number\">77</span>]: <span class=\"number\">2</span></span><br></pre></td></tr></table></figure>\n<ol start=\"6\">\n<li>获取最大值：<code>tensor.max()</code></li>\n</ol>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">In [<span class=\"number\">78</span>]: x.<span class=\"built_in\">max</span>()</span><br><span class=\"line\">Out[<span class=\"number\">78</span>]: tensor(<span class=\"number\">10</span>, dtype=torch.int32)</span><br></pre></td></tr></table></figure>\n<ol start=\"7\">\n<li>转置：<code>tensor.t()</code></li>\n</ol>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">In [<span class=\"number\">79</span>]: x.t()</span><br><span class=\"line\">Out[<span class=\"number\">79</span>]:</span><br><span class=\"line\">tensor([[    <span class=\"number\">1</span>,     <span class=\"number\">3</span>,     <span class=\"number\">5</span>],</span><br><span class=\"line\">        [    <span class=\"number\">2</span>,     <span class=\"number\">4</span>, \t  <span class=\"number\">10</span>]], dtype=torch.int32)</span><br></pre></td></tr></table></figure>\n<ol start=\"8\">\n<li><p><code>tensor[1,3]</code>  获取tensor中第一行第三列的值</p>\n</li>\n<li><p><code>tensor[1,3]=100</code> 对tensor中第一行第三列的位置进行赋值100</p>\n</li>\n<li><p>tensor的切片</p>\n</li>\n</ol>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">In [<span class=\"number\">101</span>]: x</span><br><span class=\"line\">Out[<span class=\"number\">101</span>]:</span><br><span class=\"line\">tensor([[<span class=\"number\">1.6437</span>, <span class=\"number\">1.9439</span>, <span class=\"number\">1.5393</span>],</span><br><span class=\"line\">        [<span class=\"number\">1.3491</span>, <span class=\"number\">1.9575</span>, <span class=\"number\">1.0552</span>],</span><br><span class=\"line\">        [<span class=\"number\">1.5106</span>, <span class=\"number\">1.0123</span>, <span class=\"number\">1.0961</span>],</span><br><span class=\"line\">        [<span class=\"number\">1.4382</span>, <span class=\"number\">1.5939</span>, <span class=\"number\">1.5012</span>],</span><br><span class=\"line\">        [<span class=\"number\">1.5267</span>, <span class=\"number\">1.4858</span>, <span class=\"number\">1.4007</span>]])</span><br><span class=\"line\"> </span><br><span class=\"line\">In [<span class=\"number\">102</span>]: x[:,<span class=\"number\">1</span>]</span><br><span class=\"line\">Out[<span class=\"number\">102</span>]: tensor([<span class=\"number\">1.9439</span>, <span class=\"number\">1.9575</span>, <span class=\"number\">1.0123</span>, <span class=\"number\">1.5939</span>, <span class=\"number\">1.4858</span>])</span><br></pre></td></tr></table></figure>\n<p>​</p>\n<h2 id=\"4-tensor的数据类型\"><a href=\"#4-tensor的数据类型\" class=\"headerlink\" title=\"4. tensor的数据类型\"></a>4. tensor的数据类型</h2><p>tensor中的数据类型非常多, 常见类型如下:</p>\n<p><img src=\"../images/1.2/tensor%E7%9A%84%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B.png\"></p>\n<p>上图中的Tensor types表示这种type的tensor是其实例</p>\n<ol>\n<li>获取tensor的数据类型:<code>tensor.dtype</code></li>\n</ol>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">In [<span class=\"number\">80</span>]: x.dtype</span><br><span class=\"line\">Out[<span class=\"number\">80</span>]: torch.int32</span><br></pre></td></tr></table></figure>\n<ol start=\"2\">\n<li>创建数据的时候指定类型</li>\n</ol>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">In [<span class=\"number\">88</span>]: torch.ones([<span class=\"number\">2</span>,<span class=\"number\">3</span>],dtype=torch.float32)</span><br><span class=\"line\">Out[<span class=\"number\">88</span>]:</span><br><span class=\"line\">tensor([[<span class=\"number\">9.1167e+18</span>, <span class=\"number\">0.0000e+00</span>, <span class=\"number\">7.8796e+15</span>],</span><br><span class=\"line\">        [<span class=\"number\">8.3097e-43</span>, <span class=\"number\">0.0000e+00</span>, -<span class=\"number\">0.0000e+00</span>]])</span><br></pre></td></tr></table></figure>\n<ol start=\"3\">\n<li>类型的修改</li>\n</ol>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">In [<span class=\"number\">17</span>]: a</span><br><span class=\"line\">Out[<span class=\"number\">17</span>]: tensor([<span class=\"number\">1</span>, <span class=\"number\">2</span>], dtype=torch.int32)</span><br><span class=\"line\"> </span><br><span class=\"line\">In [<span class=\"number\">18</span>]: a.<span class=\"built_in\">type</span>(torch.<span class=\"built_in\">float</span>)</span><br><span class=\"line\">Out[<span class=\"number\">18</span>]: tensor([<span class=\"number\">1.</span>, <span class=\"number\">2.</span>])</span><br><span class=\"line\"> </span><br><span class=\"line\">In [<span class=\"number\">19</span>]: a.double()</span><br><span class=\"line\">Out[<span class=\"number\">19</span>]: tensor([<span class=\"number\">1.</span>, <span class=\"number\">2.</span>], dtype=torch.float64)</span><br></pre></td></tr></table></figure>\n<h2 id=\"5-tensor的其他操作\"><a href=\"#5-tensor的其他操作\" class=\"headerlink\" title=\"5. tensor的其他操作\"></a>5. tensor的其他操作</h2><ol>\n<li>tensor和tensor相加</li>\n</ol>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">In [<span class=\"number\">94</span>]: x = x.new_ones(<span class=\"number\">5</span>, <span class=\"number\">3</span>, dtype=torch.<span class=\"built_in\">float</span>)</span><br><span class=\"line\"> </span><br><span class=\"line\">In [<span class=\"number\">95</span>]: y = torch.rand(<span class=\"number\">5</span>, <span class=\"number\">3</span>)</span><br><span class=\"line\"> </span><br><span class=\"line\">In [<span class=\"number\">96</span>]: x+y</span><br><span class=\"line\">Out[<span class=\"number\">96</span>]:</span><br><span class=\"line\">tensor([[<span class=\"number\">1.6437</span>, <span class=\"number\">1.9439</span>, <span class=\"number\">1.5393</span>],</span><br><span class=\"line\">        [<span class=\"number\">1.3491</span>, <span class=\"number\">1.9575</span>, <span class=\"number\">1.0552</span>],</span><br><span class=\"line\">        [<span class=\"number\">1.5106</span>, <span class=\"number\">1.0123</span>, <span class=\"number\">1.0961</span>],</span><br><span class=\"line\">        [<span class=\"number\">1.4382</span>, <span class=\"number\">1.5939</span>, <span class=\"number\">1.5012</span>],</span><br><span class=\"line\">        [<span class=\"number\">1.5267</span>, <span class=\"number\">1.4858</span>, <span class=\"number\">1.4007</span>]])</span><br><span class=\"line\">In [<span class=\"number\">98</span>]: torch.add(x,y)</span><br><span class=\"line\">Out[<span class=\"number\">98</span>]:</span><br><span class=\"line\">tensor([[<span class=\"number\">1.6437</span>, <span class=\"number\">1.9439</span>, <span class=\"number\">1.5393</span>],</span><br><span class=\"line\">        [<span class=\"number\">1.3491</span>, <span class=\"number\">1.9575</span>, <span class=\"number\">1.0552</span>],</span><br><span class=\"line\">        [<span class=\"number\">1.5106</span>, <span class=\"number\">1.0123</span>, <span class=\"number\">1.0961</span>],</span><br><span class=\"line\">        [<span class=\"number\">1.4382</span>, <span class=\"number\">1.5939</span>, <span class=\"number\">1.5012</span>],</span><br><span class=\"line\">        [<span class=\"number\">1.5267</span>, <span class=\"number\">1.4858</span>, <span class=\"number\">1.4007</span>]])</span><br><span class=\"line\">In [<span class=\"number\">99</span>]: x.add(y)</span><br><span class=\"line\">Out[<span class=\"number\">99</span>]:</span><br><span class=\"line\">tensor([[<span class=\"number\">1.6437</span>, <span class=\"number\">1.9439</span>, <span class=\"number\">1.5393</span>],</span><br><span class=\"line\">        [<span class=\"number\">1.3491</span>, <span class=\"number\">1.9575</span>, <span class=\"number\">1.0552</span>],</span><br><span class=\"line\">        [<span class=\"number\">1.5106</span>, <span class=\"number\">1.0123</span>, <span class=\"number\">1.0961</span>],</span><br><span class=\"line\">        [<span class=\"number\">1.4382</span>, <span class=\"number\">1.5939</span>, <span class=\"number\">1.5012</span>],</span><br><span class=\"line\">        [<span class=\"number\">1.5267</span>, <span class=\"number\">1.4858</span>, <span class=\"number\">1.4007</span>]])</span><br><span class=\"line\">In [<span class=\"number\">100</span>]: x.add_(y)  <span class=\"comment\">#带下划线的方法会对x进行就地修改</span></span><br><span class=\"line\">Out[<span class=\"number\">100</span>]:</span><br><span class=\"line\">tensor([[<span class=\"number\">1.6437</span>, <span class=\"number\">1.9439</span>, <span class=\"number\">1.5393</span>],</span><br><span class=\"line\">        [<span class=\"number\">1.3491</span>, <span class=\"number\">1.9575</span>, <span class=\"number\">1.0552</span>],</span><br><span class=\"line\">        [<span class=\"number\">1.5106</span>, <span class=\"number\">1.0123</span>, <span class=\"number\">1.0961</span>],</span><br><span class=\"line\">        [<span class=\"number\">1.4382</span>, <span class=\"number\">1.5939</span>, <span class=\"number\">1.5012</span>],</span><br><span class=\"line\">        [<span class=\"number\">1.5267</span>, <span class=\"number\">1.4858</span>, <span class=\"number\">1.4007</span>]])</span><br><span class=\"line\"> </span><br><span class=\"line\">In [<span class=\"number\">101</span>]: x <span class=\"comment\">#x发生改变</span></span><br><span class=\"line\">Out[<span class=\"number\">101</span>]:</span><br><span class=\"line\">tensor([[<span class=\"number\">1.6437</span>, <span class=\"number\">1.9439</span>, <span class=\"number\">1.5393</span>],</span><br><span class=\"line\">        [<span class=\"number\">1.3491</span>, <span class=\"number\">1.9575</span>, <span class=\"number\">1.0552</span>],</span><br><span class=\"line\">        [<span class=\"number\">1.5106</span>, <span class=\"number\">1.0123</span>, <span class=\"number\">1.0961</span>],</span><br><span class=\"line\">        [<span class=\"number\">1.4382</span>, <span class=\"number\">1.5939</span>, <span class=\"number\">1.5012</span>],</span><br><span class=\"line\">        [<span class=\"number\">1.5267</span>, <span class=\"number\">1.4858</span>, <span class=\"number\">1.4007</span>]])</span><br></pre></td></tr></table></figure>\n<p>   注意: 带下划线的方法(比如: <code>add_</code> )会对tensor进行就地修改</p>\n<ol start=\"2\">\n<li>tensor和数字操作</li>\n</ol>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">In [<span class=\"number\">97</span>]: x +<span class=\"number\">10</span></span><br><span class=\"line\">Out[<span class=\"number\">97</span>]:</span><br><span class=\"line\">tensor([[<span class=\"number\">11.</span>, <span class=\"number\">11.</span>, <span class=\"number\">11.</span>],</span><br><span class=\"line\">        [<span class=\"number\">11.</span>, <span class=\"number\">11.</span>, <span class=\"number\">11.</span>],</span><br><span class=\"line\">        [<span class=\"number\">11.</span>, <span class=\"number\">11.</span>, <span class=\"number\">11.</span>],</span><br><span class=\"line\">        [<span class=\"number\">11.</span>, <span class=\"number\">11.</span>, <span class=\"number\">11.</span>],</span><br><span class=\"line\">        [<span class=\"number\">11.</span>, <span class=\"number\">11.</span>, <span class=\"number\">11.</span>]])</span><br></pre></td></tr></table></figure>\n<ol start=\"3\">\n<li><p>CUDA中的tensor</p>\n<p>CUDA(Compute Unified Device Architecture), 是NVIDIA推出的运算平台. CUDA™是一种由NVIDIA推出的通用并行计算架构, 该架构使GPU能够解决复杂的计算问题.</p>\n</li>\n</ol>\n<p><code>torch.cuda</code> 这个模块增加了对CUDA tensor的支持, 能够在cpu和gpu上使用相同的方法操作tensor</p>\n<p>   通过 <code>.to</code> 方法能够把一个tensor转移到另外一个设备(比如从CPU转到GPU)</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#device = torch.device(&quot;cuda:0&quot; if torch.cuda.is_available() else &quot;cpu&quot;)</span></span><br><span class=\"line\"><span class=\"keyword\">if</span> torch.cuda.is_available():</span><br><span class=\"line\">    device = torch.device(<span class=\"string\">&quot;cuda&quot;</span>)          <span class=\"comment\"># cuda device对象</span></span><br><span class=\"line\">    y = torch.ones_like(x, device=device)  <span class=\"comment\"># 创建一个在cuda上的tensor</span></span><br><span class=\"line\">    x = x.to(device)                       <span class=\"comment\"># 使用方法把x转为cuda 的tensor</span></span><br><span class=\"line\">    z = x + y</span><br><span class=\"line\">    print(z)</span><br><span class=\"line\">    print(z.to(<span class=\"string\">&quot;cpu&quot;</span>, torch.double))       <span class=\"comment\"># .to方法也能够同时设置类型</span></span><br><span class=\"line\"></span><br><span class=\"line\">&gt;&gt;tensor([<span class=\"number\">1.9806</span>], device=<span class=\"string\">&#x27;cuda:0&#x27;</span>)</span><br><span class=\"line\">&gt;&gt;tensor([<span class=\"number\">1.9806</span>], dtype=torch.float64)</span><br></pre></td></tr></table></figure>\n<p>通过前面的学习, 可以发现torch的各种操作几乎和numpy一样</p>\n","categories":[{"name":"python","path":"api/categories/python.json"}],"tags":[]}